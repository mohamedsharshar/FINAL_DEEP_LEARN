# ğŸ¯ Ù…Ø´Ø±ÙˆØ¹ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… LSTM - Emoji Predictor

## ğŸ“‹ Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø© Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹

Ù‡Ø°Ø§ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø¹Ø¨Ø§Ø±Ø© Ø¹Ù† Ù†Ø¸Ø§Ù… **ØªØ­Ù„ÙŠÙ„ Ù…Ø´Ø§Ø¹Ø± (Sentiment Analysis)** ÙŠØ³ØªØ®Ø¯Ù… Ø´Ø¨ÙƒØ§Øª **LSTM (Long Short-Term Memory)** Ù„Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ù€ Emoji Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ Ù„Ø£ÙŠ Ø¬Ù…Ù„Ø© Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©.

### ğŸ¯ Ù‡Ø¯Ù Ø§Ù„Ù…Ø´Ø±ÙˆØ¹
- Ø¥Ø¯Ø®Ø§Ù„ Ø¬Ù…Ù„Ø© Ù…Ø«Ù„: `"I love you"`
- Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙŠØªÙ†Ø¨Ø£ Ø¨Ø§Ù„Ù€ emoji Ø§Ù„Ù…Ù†Ø§Ø³Ø¨: â¤ï¸

### ğŸ“Š Ø§Ù„Ù€ Emojis Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© (5 ÙØ¦Ø§Øª)
| Ø§Ù„Ø±Ù‚Ù… | Emoji | Ø§Ù„Ù…Ø¹Ù†Ù‰ |
|-------|-------|--------|
| 0 | â¤ï¸ | Ø­Ø¨ |
| 1 | âš¾ | Ø±ÙŠØ§Ø¶Ø© |
| 2 | ğŸ˜„ | Ø³Ø¹Ø§Ø¯Ø© |
| 3 | ğŸ˜ | Ø­Ø²Ù† |
| 4 | ğŸ´ | Ø·Ø¹Ø§Ù… |

---

## ğŸ§  Ù…Ø§ Ù‡Ùˆ RNNØŸ

**RNN (Recurrent Neural Network)** Ù‡ÙŠ Ø´Ø¨ÙƒØ© Ø¹ØµØ¨ÙŠØ© Ù…ØµÙ…Ù…Ø© Ù„Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªØ³Ù„Ø³Ù„Ø© (Sequential Data) Ù…Ø«Ù„:
- Ø§Ù„Ù†ØµÙˆØµ (ÙƒÙ„Ù…Ø© Ø¨Ø¹Ø¯ ÙƒÙ„Ù…Ø©)
- Ø§Ù„ØµÙˆØª (Ø¥Ø´Ø§Ø±Ø© Ø¨Ø¹Ø¯ Ø¥Ø´Ø§Ø±Ø©)
- Ø§Ù„Ø³Ù„Ø§Ø³Ù„ Ø§Ù„Ø²Ù…Ù†ÙŠØ©

### Ù…Ø´ÙƒÙ„Ø© RNN Ø§Ù„ØªÙ‚Ù„ÙŠØ¯ÙŠØ©
- **Vanishing Gradient Problem**: Ø¹Ù†Ø¯ Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ø·ÙˆÙŠÙ„Ø©ØŒ Ø§Ù„Ø´Ø¨ÙƒØ© "ØªÙ†Ø³Ù‰" Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø£ÙˆÙ„Ù‰
- Ù…Ø«Ø§Ù„: ÙÙŠ Ø¬Ù…Ù„Ø© Ø·ÙˆÙŠÙ„Ø©ØŒ RNN Ù‚Ø¯ ØªÙ†Ø³Ù‰ Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„Ø¬Ù…Ù„Ø© Ø¹Ù†Ø¯ Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù„Ù†Ù‡Ø§ÙŠØ©

---

## ğŸ”¥ Ù…Ø§ Ù‡Ùˆ LSTMØŸ

**LSTM (Long Short-Term Memory)** Ù‡Ùˆ Ù†ÙˆØ¹ Ù…ØªØ·ÙˆØ± Ù…Ù† RNN ÙŠØ­Ù„ Ù…Ø´ÙƒÙ„Ø© Ø§Ù„Ù†Ø³ÙŠØ§Ù† Ø¹Ù† Ø·Ø±ÙŠÙ‚:

### Ù…ÙƒÙˆÙ†Ø§Øª LSTM
1. **Forget Gate (Ø¨ÙˆØ§Ø¨Ø© Ø§Ù„Ù†Ø³ÙŠØ§Ù†)**: ØªÙ‚Ø±Ø± Ø£ÙŠ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù†ØªØ®Ù„Øµ Ù…Ù†Ù‡Ø§
2. **Input Gate (Ø¨ÙˆØ§Ø¨Ø© Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„)**: ØªÙ‚Ø±Ø± Ø£ÙŠ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¬Ø¯ÙŠØ¯Ø© Ù†Ø¶ÙŠÙÙ‡Ø§
3. **Output Gate (Ø¨ÙˆØ§Ø¨Ø© Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬)**: ØªÙ‚Ø±Ø± Ù…Ø§Ø°Ø§ Ù†Ø®Ø±Ø¬ ÙƒÙ†ØªÙŠØ¬Ø©
4. **Cell State (Ø­Ø§Ù„Ø© Ø§Ù„Ø®Ù„ÙŠØ©)**: Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø·ÙˆÙŠÙ„Ø© Ø§Ù„Ù…Ø¯Ù‰

### Ù„Ù…Ø§Ø°Ø§ LSTM Ø£ÙØ¶Ù„ØŸ
```
RNN Ø§Ù„ØªÙ‚Ù„ÙŠØ¯ÙŠØ©:  "I love you" â†’ Ù‚Ø¯ ØªÙ†Ø³Ù‰ "I" Ø¹Ù†Ø¯ Ù…Ø¹Ø§Ù„Ø¬Ø© "you"
LSTM:          "I love you" â†’ ØªØªØ°ÙƒØ± ÙƒÙ„ Ø§Ù„ÙƒÙ„Ù…Ø§Øª ÙˆØ¹Ù„Ø§Ù‚ØªÙ‡Ø§ Ø¨Ø¨Ø¹Ø¶
```

---

## ğŸ“ Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹

```
ğŸ“¦ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹
â”œâ”€â”€ ğŸ“„ main.py              # Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
â”œâ”€â”€ ğŸ“„ emo_utils.py         # Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø©
â”œâ”€â”€ ğŸ“„ train_emoji.csv      # Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨
â”œâ”€â”€ ğŸ“„ test_emoji.csv       # Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
â”œâ”€â”€ ğŸ“„ glove.6B.50d.txt     # Word Embeddings
â””â”€â”€ ğŸ“„ emojify_data.csv     # Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£ØµÙ„ÙŠØ©
```

---

## ğŸ” Ø´Ø±Ø­ Ø§Ù„ÙƒÙˆØ¯ Ø³Ø·Ø± Ø¨Ø³Ø·Ø±

### 1ï¸âƒ£ Ù…Ù„Ù main.py

#### Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª
```python
import numpy as np
from keras.models import Model
from keras.layers import Dense, Input, Dropout, LSTM, Activation, Embedding
from emo_utils import *
```
- `numpy`: Ù„Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ© Ø¹Ù„Ù‰ Ø§Ù„Ù…ØµÙÙˆÙØ§Øª
- `keras.models.Model`: Ù„Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„
- `Dense`: Ø·Ø¨Ù‚Ø© fully connected
- `Input`: Ø·Ø¨Ù‚Ø© Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„
- `Dropout`: Ù„Ù…Ù†Ø¹ overfitting
- `LSTM`: Ø·Ø¨Ù‚Ø© Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø·ÙˆÙŠÙ„Ø© Ø§Ù„Ù…Ø¯Ù‰
- `Activation`: Ø¯ÙˆØ§Ù„ Ø§Ù„ØªÙ†Ø´ÙŠØ·
- `Embedding`: Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ù„Ù€ vectors

```python
np.random.seed(1)
```
- ØªØ«Ø¨ÙŠØª Ø§Ù„Ù€ random seed Ù„Ø¶Ù…Ø§Ù† Ù†ØªØ§Ø¦Ø¬ Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªÙƒØ±Ø§Ø±

---

#### Ø¯Ø§Ù„Ø© sentences_to_indices
```python
def sentences_to_indices(X, word_to_index, max_len):
```
**Ø§Ù„Ù‡Ø¯Ù**: ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ù†ØµÙŠØ© Ø¥Ù„Ù‰ Ø£Ø±Ù‚Ø§Ù… (indices) ÙŠÙÙ‡Ù…Ù‡Ø§ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„

```python
    m = X.shape[0]  # Ø¹Ø¯Ø¯ Ø§Ù„Ø¬Ù…Ù„
```
- `m`: Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ù…Ø«Ù„Ø© ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª

```python
    X_indices = np.zeros((m, max_len))
```
- Ø¥Ù†Ø´Ø§Ø¡ Ù…ØµÙÙˆÙØ© Ø£ØµÙØ§Ø± Ø¨Ø­Ø¬Ù… (Ø¹Ø¯Ø¯ Ø§Ù„Ø¬Ù…Ù„ Ã— Ø£Ù‚ØµÙ‰ Ø·ÙˆÙ„ Ù„Ù„Ø¬Ù…Ù„Ø©)
- Ù…Ø«Ø§Ù„: Ù„Ùˆ Ø¹Ù†Ø¯Ù†Ø§ 100 Ø¬Ù…Ù„Ø© ÙˆØ£Ø·ÙˆÙ„ Ø¬Ù…Ù„Ø© 10 ÙƒÙ„Ù…Ø§Øª â†’ Ù…ØµÙÙˆÙØ© 100Ã—10

```python
    for i in range(m):  # Ø§Ù„Ù…Ø±ÙˆØ± Ø¹Ù„Ù‰ ÙƒÙ„ Ø¬Ù…Ù„Ø©
        sentence_words = (X[i].lower()).split()
```
- ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¬Ù…Ù„Ø© Ù„Ù€ lowercase ÙˆØªÙ‚Ø³ÙŠÙ…Ù‡Ø§ Ù„ÙƒÙ„Ù…Ø§Øª
- Ù…Ø«Ø§Ù„: `"I Love You"` â†’ `["i", "love", "you"]`

```python
        j = 0
        for w in sentence_words:
            X_indices[i, j] = word_to_index[w]
            j = j + 1
```
- Ø§Ø³ØªØ¨Ø¯Ø§Ù„ ÙƒÙ„ ÙƒÙ„Ù…Ø© Ø¨Ø±Ù‚Ù…Ù‡Ø§ ÙÙŠ Ø§Ù„Ù‚Ø§Ù…ÙˆØ³
- Ù…Ø«Ø§Ù„: `["i", "love", "you"]` â†’ `[1234, 5678, 9012]`

```python
    return X_indices
```
- Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ù…ØµÙÙˆÙØ© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©

**Ù…Ø«Ø§Ù„ Ø¹Ù…Ù„ÙŠ:**
```
Input:  ["I love you", "I am happy"]
Output: [[1234, 5678, 9012, 0, 0, 0, 0, 0, 0, 0],
         [1234, 234, 7890, 0, 0, 0, 0, 0, 0, 0]]
```
(Ø§Ù„Ø£ØµÙØ§Ø± = padding Ù„ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø·ÙˆÙ„)

---

#### Ø¯Ø§Ù„Ø© pretrained_embedding_layer
```python
def pretrained_embedding_layer(word_to_vec_map, word_to_index):
```
**Ø§Ù„Ù‡Ø¯Ù**: Ø¥Ù†Ø´Ø§Ø¡ Ø·Ø¨Ù‚Ø© Embedding Ù…Ø­Ù…Ù„Ø© Ø¨Ù€ GloVe vectors

```python
    vocab_len = len(word_to_index) + 1
```
- Ø­Ø¬Ù… Ø§Ù„Ù…ÙØ±Ø¯Ø§Øª + 1 (Ù„Ø£Ù† Keras ÙŠØ¨Ø¯Ø£ Ù…Ù† 1 Ù…Ø´ 0)
- ÙÙŠ Ø­Ø§Ù„ØªÙ†Ø§: ~400,000 ÙƒÙ„Ù…Ø©

```python
    emb_dim = word_to_vec_map["cucumber"].shape[0]
```
- Ø£Ø¨Ø¹Ø§Ø¯ Ø§Ù„Ù€ embedding (50 ÙÙŠ Ø­Ø§Ù„ØªÙ†Ø§)
- ÙƒÙ„ ÙƒÙ„Ù…Ø© Ù…Ù…Ø«Ù„Ø© Ø¨Ù€ 50 Ø±Ù‚Ù…

```python
    emb_matrix = np.zeros((vocab_len, emb_dim))
```
- Ø¥Ù†Ø´Ø§Ø¡ Ù…ØµÙÙˆÙØ© Ø§Ù„Ù€ embeddings
- Ø§Ù„Ø­Ø¬Ù…: 400,001 Ã— 50

```python
    for word, index in word_to_index.items():
        emb_matrix[index, :] = word_to_vec_map[word]
```
- Ù…Ù„Ø¡ Ø§Ù„Ù…ØµÙÙˆÙØ© Ø¨Ù€ vectors Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ù…Ù† GloVe
- ÙƒÙ„ ØµÙ = vector ÙƒÙ„Ù…Ø© ÙˆØ§Ø­Ø¯Ø©

```python
    embedding_layer = Embedding(vocab_len, emb_dim)
    embedding_layer.build((None,))
    embedding_layer.set_weights([emb_matrix])
```
- Ø¥Ù†Ø´Ø§Ø¡ Ø·Ø¨Ù‚Ø© Embedding ÙÙŠ Keras
- ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù€ weights Ø§Ù„Ø¬Ø§Ù‡Ø²Ø© Ù…Ù† GloVe

```python
    return embedding_layer
```

**Ù…Ø§ Ù‡Ùˆ GloVeØŸ**
- GloVe = Global Vectors for Word Representation
- ÙƒÙ„ ÙƒÙ„Ù…Ø© Ù„Ù‡Ø§ vector ÙŠÙ…Ø«Ù„ Ù…Ø¹Ù†Ø§Ù‡Ø§
- Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ØªØ´Ø§Ø¨Ù‡Ø© Ù„Ù‡Ø§ vectors Ù‚Ø±ÙŠØ¨Ø©
```
king  â†’ [0.52, -0.31, 0.18, ...]
queen â†’ [0.49, -0.28, 0.21, ...]  (Ù‚Ø±ÙŠØ¨Ø© Ù…Ù† king)
apple â†’ [0.12, 0.85, -0.42, ...]  (Ø¨Ø¹ÙŠØ¯Ø© Ø¹Ù† king)
```

---

#### Ø¯Ø§Ù„Ø© SentimentAnalysis (Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ)
```python
def SentimentAnalysis(input_shape, word_to_vec_map, word_to_index):
```
**Ø§Ù„Ù‡Ø¯Ù**: Ø¨Ù†Ø§Ø¡ Ù…ÙˆØ¯ÙŠÙ„ LSTM Ù„Ù„ØªØµÙ†ÙŠÙ

```python
    sentence_indices = Input(shape=input_shape, dtype=np.int32)
```
- Ø·Ø¨Ù‚Ø© Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„
- Ø§Ù„Ø´ÙƒÙ„: (max_len,) = (10,) ÙÙŠ Ø­Ø§Ù„ØªÙ†Ø§
- Ø§Ù„Ù†ÙˆØ¹: Ø£Ø±Ù‚Ø§Ù… ØµØ­ÙŠØ­Ø© (indices Ø§Ù„ÙƒÙ„Ù…Ø§Øª)

```python
    embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)
    embeddings = embedding_layer(sentence_indices)
```
- ØªÙ…Ø±ÙŠØ± Ø§Ù„Ù€ indices Ø®Ù„Ø§Ù„ Ø·Ø¨Ù‚Ø© Embedding
- Ø§Ù„ØªØ­ÙˆÙŠÙ„: Ø£Ø±Ù‚Ø§Ù… â†’ vectors
- Ø§Ù„Ø´ÙƒÙ„: (batch, 10) â†’ (batch, 10, 50)

```python
    X = LSTM(128, return_sequences=True)(embeddings)
```
- **Ø£ÙˆÙ„ Ø·Ø¨Ù‚Ø© LSTM**
- 128 = Ø¹Ø¯Ø¯ Ø§Ù„Ù€ hidden units
- `return_sequences=True` = Ø¥Ø±Ø¬Ø§Ø¹ output Ù„ÙƒÙ„ ÙƒÙ„Ù…Ø©
- Ø§Ù„Ø´ÙƒÙ„: (batch, 10, 50) â†’ (batch, 10, 128)

```python
    X = Dropout(0.5)(X)
```
- **Dropout Ù„Ù„ØªÙ†Ø¸ÙŠÙ…**
- 50% Ù…Ù† Ø§Ù„Ù€ neurons ÙŠØªÙ… ØªØ¬Ø§Ù‡Ù„Ù‡Ø§ Ø¹Ø´ÙˆØ§Ø¦ÙŠØ§Ù‹ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
- ÙŠÙ…Ù†Ø¹ overfitting

```python
    X = LSTM(128)(X)
```
- **Ø«Ø§Ù†ÙŠ Ø·Ø¨Ù‚Ø© LSTM**
- `return_sequences=False` (Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ) = Ø¥Ø±Ø¬Ø§Ø¹ Ø¢Ø®Ø± output ÙÙ‚Ø·
- Ø§Ù„Ø´ÙƒÙ„: (batch, 10, 128) â†’ (batch, 128)

```python
    X = Dropout(0.5)(X)
```
- Dropout ØªØ§Ù†ÙŠ

```python
    X = Dense(5, activation='softmax')(X)
```
- **Ø·Ø¨Ù‚Ø© Dense Ù„Ù„ØªØµÙ†ÙŠÙ**
- 5 = Ø¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª (5 emojis)
- softmax = Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª Ù„ÙƒÙ„ ÙØ¦Ø©
- Ø§Ù„Ø´ÙƒÙ„: (batch, 128) â†’ (batch, 5)

```python
    X = Activation('softmax')(X)
```
- ØªØ·Ø¨ÙŠÙ‚ softmax Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ (Ù…Ù„Ø§Ø­Ø¸Ø©: Ù‡Ø°Ø§ ØªÙƒØ±Ø§Ø± ØºÙŠØ± Ø¶Ø±ÙˆØ±ÙŠ)

```python
    model = Model(sentence_indices, X)
    return model
```
- Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ

---

#### Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ (main)
```python
if __name__ == "__main__":
```
- ÙŠØªÙ… ØªÙ†ÙÙŠØ° Ù‡Ø°Ø§ Ø§Ù„ÙƒÙˆØ¯ ÙÙ‚Ø· Ø¹Ù†Ø¯ ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ù…Ø¨Ø§Ø´Ø±Ø©

```python
    X_train, Y_train = read_csv('train_emoji.csv')
    X_test, Y_test = read_csv('test_emoji.csv')
```
- Ù‚Ø±Ø§Ø¡Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„Ø§Ø®ØªØ¨Ø§Ø±
- X = Ø§Ù„Ø¬Ù…Ù„ØŒ Y = Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù€ emojis

```python
    maxLen = len(max(X_train, key=len).split())
```
- Ø­Ø³Ø§Ø¨ Ø£Ø·ÙˆÙ„ Ø¬Ù…Ù„Ø© ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
- ÙÙŠ Ø­Ø§Ù„ØªÙ†Ø§: 10 ÙƒÙ„Ù…Ø§Øª

```python
    Y_oh_train = convert_to_one_hot(Y_train, C=5)
    Y_oh_test = convert_to_one_hot(Y_test, C=5)
```
- ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù€ labels Ù„Ù€ one-hot encoding
- Ù…Ø«Ø§Ù„: `2` â†’ `[0, 0, 1, 0, 0]`

```python
    word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('glove.6B.50d.txt')
```
- Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù GloVe
- `word_to_index`: Ù‚Ø§Ù…ÙˆØ³ ÙƒÙ„Ù…Ø© â†’ Ø±Ù‚Ù…
- `index_to_word`: Ù‚Ø§Ù…ÙˆØ³ Ø±Ù‚Ù… â†’ ÙƒÙ„Ù…Ø©
- `word_to_vec_map`: Ù‚Ø§Ù…ÙˆØ³ ÙƒÙ„Ù…Ø© â†’ vector

```python
    model = SentimentAnalysis((maxLen,), word_to_vec_map, word_to_index)
    model.summary()
```
- Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙˆØ·Ø¨Ø§Ø¹Ø© Ù…Ù„Ø®ØµÙ‡

```python
    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
```
- ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ù„Ù„ØªØ¯Ø±ÙŠØ¨
- `categorical_crossentropy`: loss function Ù„Ù„ØªØµÙ†ÙŠÙ Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª
- `adam`: optimizer Ø³Ø±ÙŠØ¹ ÙˆÙØ¹Ø§Ù„
- `accuracy`: Ø§Ù„Ù…Ù‚ÙŠØ§Ø³ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…

```python
    X_train_indices = sentences_to_indices(X_train, word_to_index, maxLen)
    Y_train_oh = convert_to_one_hot(Y_train, C=5)
```
- ØªØ­Ø¶ÙŠØ± Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨

```python
    model.fit(X_train_indices, Y_train_oh, epochs=100, batch_size=32, shuffle=True)
```
- **ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„**
- `epochs=100`: Ø§Ù„Ù…Ø±ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª 100 Ù…Ø±Ø©
- `batch_size=32`: ØªØ¯Ø±ÙŠØ¨ 32 Ù…Ø«Ø§Ù„ ÙÙŠ ÙƒÙ„ Ø®Ø·ÙˆØ©
- `shuffle=True`: Ø®Ù„Ø· Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ ÙƒÙ„ epoch

```python
    loss, acc = model.evaluate(X_test_indices, Y_test_oh)
    print("Test accuracy = ", acc)
```
- ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±

```python
    pred = model.predict(X_test_indices)
    for i in range(len(X_test)):
        num = np.argmax(pred[i])
        if (num != Y_test[i]):
            print('Expected emoji:' + label_to_emoji(Y_test[i]) + 
                  ' prediction: ' + X_test[i] + label_to_emoji(num).strip())
```
- Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„ØªÙŠ Ø£Ø®Ø·Ø£ ÙÙŠÙ‡Ø§ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„

```python
    x_test = np.array(['very happy'])
    X_test_indices = sentences_to_indices(x_test, word_to_index, maxLen)
    print(x_test[0] + ' ' + label_to_emoji(np.argmax(model.predict(X_test_indices))))
```
- Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø¹Ù„Ù‰ Ø¬Ù…Ù„Ø© Ø¬Ø¯ÙŠØ¯Ø©

---

### 2ï¸âƒ£ Ù…Ù„Ù emo_utils.py

#### Ø¯Ø§Ù„Ø© read_glove_vecs
```python
def read_glove_vecs(glove_file):
    with open(glove_file, 'r', encoding="utf8") as f:
        words = set()
        word_to_vec_map = {}
```
- ÙØªØ­ Ù…Ù„Ù GloVe ÙˆØªØ¬Ù‡ÙŠØ² Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª

```python
        for line in f:
            line = line.strip().split()
            curr_word = line[0]
            words.add(curr_word)
            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)
```
- Ù‚Ø±Ø§Ø¡Ø© ÙƒÙ„ Ø³Ø·Ø± ÙÙŠ Ø§Ù„Ù…Ù„Ù
- ÙƒÙ„ Ø³Ø·Ø±: `ÙƒÙ„Ù…Ø© Ø±Ù‚Ù…1 Ø±Ù‚Ù…2 ... Ø±Ù‚Ù…50`
- ØªØ®Ø²ÙŠÙ† Ø§Ù„ÙƒÙ„Ù…Ø© ÙˆØ§Ù„Ù€ vector Ø§Ù„Ø®Ø§Øµ Ø¨Ù‡Ø§

```python
        i = 1
        words_to_index = {}
        index_to_words = {}
        for w in sorted(words):
            words_to_index[w] = i
            index_to_words[i] = w
            i = i + 1
```
- Ø¥Ù†Ø´Ø§Ø¡ Ù‚ÙˆØ§Ù…ÙŠØ³ Ù„Ù„ØªØ­ÙˆÙŠÙ„ Ø¨ÙŠÙ† Ø§Ù„ÙƒÙ„Ù…Ø§Øª ÙˆØ§Ù„Ø£Ø±Ù‚Ø§Ù…

---

#### Ø¯Ø§Ù„Ø© read_csv
```python
def read_csv(filename = 'emojify_data.csv'):
    phrase = []
    emoji = []
    with open (filename) as csvDataFile:
        csvReader = csv.reader(csvDataFile)
        for row in csvReader:
            phrase.append(row[0])
            emoji.append(row[1])
    X = np.asarray(phrase)
    Y = np.asarray(emoji, dtype=int)
    return X, Y
```
- Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù CSV
- Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ø¬Ù…Ù„ (X) ÙˆØ§Ù„Ù€ labels (Y)

---

#### Ø¯Ø§Ù„Ø© convert_to_one_hot
```python
def convert_to_one_hot(Y, C):
    Y = np.eye(C)[Y.reshape(-1)]
    return Y
```
- ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ù„Ù€ one-hot vectors
- `np.eye(C)` = Ù…ØµÙÙˆÙØ© ÙˆØ­Ø¯Ø© CÃ—C
- Ù…Ø«Ø§Ù„: `Y=[0,2,1]`, `C=3`
```
np.eye(3) = [[1,0,0],
             [0,1,0],
             [0,0,1]]

Y[0]=0 â†’ [1,0,0]
Y[1]=2 â†’ [0,0,1]
Y[2]=1 â†’ [0,1,0]
```

---

#### Ø¯Ø§Ù„Ø© label_to_emoji
```python
emoji_dictionary = {"0": "\u2764\uFE0F",    # â¤ï¸
                    "1": ":baseball:",       # âš¾
                    "2": ":smile:",          # ğŸ˜„
                    "3": ":disappointed:",   # ğŸ˜
                    "4": ":fork_and_knife:"} # ğŸ´

def label_to_emoji(label):
    return emoji.emojize(emoji_dictionary[str(label)], language='alias')
```
- ØªØ­ÙˆÙŠÙ„ Ø±Ù‚Ù… Ø§Ù„ÙØ¦Ø© Ù„Ù„Ù€ emoji Ø§Ù„Ù…Ù‚Ø§Ø¨Ù„

---

## ğŸ—ï¸ Ù…Ø¹Ù…Ø§Ø±ÙŠØ© Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Input Layer                               â”‚
â”‚                    Shape: (10,)                              â”‚
â”‚            [ÙƒÙ„Ù…Ø©1, ÙƒÙ„Ù…Ø©2, ..., ÙƒÙ„Ù…Ø©10]                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Embedding Layer                             â”‚
â”‚              Shape: (10, 50)                                 â”‚
â”‚         ÙƒÙ„ ÙƒÙ„Ù…Ø© â†’ vector Ù…Ù† 50 Ø±Ù‚Ù…                          â”‚
â”‚              Parameters: 20,000,050                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LSTM Layer 1                              â”‚
â”‚              Shape: (10, 128)                                â”‚
â”‚         return_sequences=True                                â”‚
â”‚              Parameters: 91,648                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Dropout (50%)                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LSTM Layer 2                              â”‚
â”‚              Shape: (128,)                                   â”‚
â”‚         return_sequences=False                               â”‚
â”‚              Parameters: 131,584                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Dropout (50%)                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Dense Layer                               â”‚
â”‚              Shape: (5,)                                     â”‚
â”‚         activation='softmax'                                 â”‚
â”‚              Parameters: 645                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Output                                  â”‚
â”‚         [P(â¤ï¸), P(âš¾), P(ğŸ˜„), P(ğŸ˜), P(ğŸ´)]                  â”‚
â”‚              Ø§Ø­ØªÙ…Ø§Ù„ ÙƒÙ„ emoji                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ˆ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ¯Ø±ÙŠØ¨

```
Training Accuracy: ~98.5%
Test Accuracy: 87.5%
Total Parameters: 20,223,927
```

### Ø£Ù…Ø«Ù„Ø© Ø¹Ù„Ù‰ Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª
| Ø§Ù„Ø¬Ù…Ù„Ø© | Ø§Ù„Ù…ØªÙˆÙ‚Ø¹ | Ø§Ù„ØªÙ†Ø¨Ø¤ |
|--------|---------|--------|
| "very happy" | ğŸ˜„ | ğŸ˜„ âœ… |
| "I love you" | â¤ï¸ | â¤ï¸ âœ… |
| "go away" | ğŸ˜ | âš¾ âŒ |

---

## ğŸ”§ ÙƒÙŠÙÙŠØ© ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹

1. ØªØ«Ø¨ÙŠØª Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª:
```bash
pip install tensorflow keras numpy pandas matplotlib scikit-learn emoji
```

2. ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù GloVe:
   - Ù…Ù†: https://nlp.stanford.edu/data/glove.6B.zip
   - ÙÙƒ Ø§Ù„Ø¶ØºØ· ÙˆÙ†Ø³Ø® `glove.6B.50d.txt` Ù„Ù„Ù…Ø´Ø±ÙˆØ¹

3. ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹:
```bash
python main.py
```

---

## ğŸ“š Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹

- [Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)
- [GloVe: Global Vectors for Word Representation](https://nlp.stanford.edu/projects/glove/)
- [Keras Documentation](https://keras.io/)

---

## âœï¸ Ù…Ù„Ø®Øµ

Ù‡Ø°Ø§ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ ÙŠÙˆØ¶Ø­ ÙƒÙŠÙÙŠØ© Ø§Ø³ØªØ®Ø¯Ø§Ù… LSTM Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± ÙÙŠ Ø§Ù„Ù†ØµÙˆØµ. Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙŠØªØ¹Ù„Ù… Ù…Ù† Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ù…ØµÙ†ÙØ© ÙˆÙŠØ³ØªØ·ÙŠØ¹ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ù€ emoji Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ Ù„Ø£ÙŠ Ø¬Ù…Ù„Ø© Ø¬Ø¯ÙŠØ¯Ø©. Ø§Ø³ØªØ®Ø¯Ø§Ù… GloVe embeddings ÙŠØ³Ø§Ø¹Ø¯ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø¹Ù„Ù‰ ÙÙ‡Ù… Ù…Ø¹Ø§Ù†ÙŠ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø¨Ø¯ÙˆÙ† Ø§Ù„Ø­Ø§Ø¬Ø© Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¶Ø®Ù…Ø© Ù„Ù„ØªØ¯Ø±ÙŠØ¨.
